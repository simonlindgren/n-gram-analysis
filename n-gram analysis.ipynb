{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook was posted by Simon Lindgren // [@simonlindgren](http://www.twitter.com/simonlindgren) // [simonlindgren.com](http://simonlindgren.com)\n",
    "\n",
    "It is about stuff that can be done with the `tidytext` package, if we tokenize by consecutive sequences of words ([n-grams](https://en.wikipedia.org/wiki/N-gram)), rather than just by single words. \n",
    "\n",
    "The code below is based on the book [Text Mining with R](http://tidytextmining.com) by [Julia Silge](http://juliasilge.com) and [David Robinson](http://varianceexplained.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidytext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read documents\n",
    "The code below reads a `csv` file into a tidy dataset. We use `unnest_tokens()` with the `ngram` option to get ngrams of `n` consecutive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents <- read_csv2(\"tidyraw2.csv\")\n",
    "tidy_documents <- documents %>%\n",
    "    #unnest_tokens(word,text) \n",
    "    unnest_tokens(bigram, text, token = \"ngrams\", n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspect the dataframe\n",
    "tidy_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common bigrams\n",
    "tidy_documents %>%\n",
    "  count(bigram, sort = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of those were stopword-type words. We use `tidyr`'s `separate()` function to split the column 'bigram' into 'word 1' and 'word 2' based on the blank space as a separator between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_separated <- tidy_documents %>%\n",
    "  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n",
    "bigrams_separated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, remove all rows that have any of `tidytext`'s stopwords in any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_filtered <- bigrams_separated %>%\n",
    "  filter(!word1 %in% stop_words$word) %>%\n",
    "  filter(!word2 %in% stop_words$word)\n",
    "bigrams_filtered\n",
    "\n",
    "# This can also be done with own custom list of stopwords:\n",
    "# Read your own stops: my_stop_words <- read_csv2(\"swestop.csv\")\n",
    "# use that instead of stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new bigram counts:\n",
    "bigram_counts <- bigrams_filtered %>% \n",
    "  count(word1, word2, sort = TRUE)\n",
    "\n",
    "bigram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After stopword removal, we might want to recombine the bigrams into one column again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_united <- bigrams_filtered %>%\n",
    "  unite(bigram, word1, word2, sep = \" \")\n",
    "\n",
    "bigrams_united"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((The same process but with trigrams))\n",
    "documents <- read_csv2(\"tidyraw2.csv\")\n",
    "trigram_documents <- documents %>%\n",
    "    unnest_tokens(trigram, text, token = \"ngrams\", n = 3) %>%\n",
    "    separate(trigram, c(\"word1\", \"word2\", \"word3\"), sep = \" \") %>%\n",
    "    filter(!word1 %in% stop_words$word,\n",
    "         !word2 %in% stop_words$word,\n",
    "         !word3 %in% stop_words$word) %>%\n",
    "    count(word1, word2, word3, sort = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((recombine trigrams into one column again))\n",
    "trigrams_united <- trigram_documents %>%\n",
    "  unite(trigram, word1, word2, word3, sep = \" \")\n",
    "\n",
    "trigrams_united"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exploratory analysis of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Back to the bigrams\n",
    "# What are the most common pairs with word x as word1 or 2?\n",
    "# We use the non united columns for that\n",
    "\n",
    "bigrams_filtered %>%\n",
    "  filter(word2 == \"awoke\") %>%\n",
    "  count(blogger, word1, sort = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can do similar things such as with single words\n",
    "# For example look at the tf-idf of bigrams across the documents\n",
    "# We use the united column for that\n",
    "\n",
    "bigram_tf_idf <- bigrams_united %>%\n",
    "  count(blogger, bigram) %>%\n",
    "  bind_tf_idf(bigram, blogger, n) %>%\n",
    "  arrange(desc(tf_idf))\n",
    "\n",
    "bigram_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualise the high tf-idf bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_plot <- bigram_tf_idf %>%\n",
    "    arrange(desc(tf_idf)) %>%\n",
    "    mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) \n",
    "\n",
    "my_plot %>%\n",
    "    top_n(2) %>%\n",
    "    ggplot(aes(bigram, tf_idf, fill = blogger)) +\n",
    "    geom_col() +\n",
    "    labs(x = NULL, y = \"tf-idf\") +\n",
    "    coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we look at blogs individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_plot %>% \n",
    "  group_by(blogger) %>% \n",
    "  top_n(5) %>% \n",
    "  ungroup %>%\n",
    "  ggplot(aes(bigram, tf_idf, fill = blogger)) +\n",
    "  geom_col(show.legend = FALSE) +\n",
    "  labs(x = NULL, y = \"tf-idf\") +\n",
    "  facet_wrap(~blogger, ncol = 2, scales = \"free\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualising bigrams in a graph\n",
    "A network graph can be constructed from a tidy object since it has three variables:\n",
    "\n",
    "- source: the node an edge is coming from\n",
    "- target: the node an edge is going towards\n",
    "- weight: A numeric value associated with each edge\n",
    "\n",
    "We use the `igraph` package and its function `graph_from_data_frame()`. Our dataframe `bigram_counts` from earlier has columns corresponding to 'source', 'target', and 'edge weight' (in this case: `n`).\n",
    "\n",
    "You may run into problems installing `igraph` via CRAN, but if you use Anaconda you can do: `conda install r-igraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(igraph)\n",
    "bigram_counts # dataframe from before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter for the most common pairs (edges), and create the network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_graph <- bigram_counts %>%\n",
    "  filter(n > 1) %>% # filter edges with weight above x\n",
    "  graph_from_data_frame()\n",
    "\n",
    "bigram_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ggraph` package is better than `igraph` at the visualisation bit, so let's use that one to draw the graph. Installing `ggraph` can be tricky, but [this](https://stackoverflow.com/questions/42315364/how-to-install-ggraph-package-to-the-latest-r-v-3-3-2) may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggraph)\n",
    "ggraph(bigram_graph, layout = \"fr\") +\n",
    "  geom_edge_link() +\n",
    "  geom_node_point() +\n",
    "  geom_node_text(aes(label = name), vjust = 1, hjust = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, tweak the graph.\n",
    "\n",
    "- add a theme that removes the wrongful axes, theme_void()\n",
    "- tinker with `geom_node_point` to make the nodes blue and larger\n",
    "- add directionality to `geom_edge_link` with an arrow, constructed using `grid::arrow()`, including an end_cap option that tells the arrow to end before touching the node\n",
    "- add the `edge_alpha` aesthetic to the link layer to make links transparent based on how common or rare the bigram is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the arrows\n",
    "a <- grid::arrow(type = \"closed\", length = unit(.10, \"inches\"))\n",
    "\n",
    "# the graph\n",
    "ggraph(bigram_graph, layout = \"fr\") +\n",
    "  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n",
    "                 arrow = a, end_cap = circle(.07, 'inches')) +\n",
    "  geom_node_point(color = \"lightblue\", size = 6) +\n",
    "  geom_node_text(aes(label = name), vjust = 1, hjust = 1)+\n",
    "  theme_void()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
